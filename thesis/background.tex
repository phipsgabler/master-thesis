\chapter{Background}
\label{cha:background}

This chapter provides background for concepts used later in chapters~\ref{cha:impl-dynam-graph} and
\ref{cha:graph-track-prob}.  It gives a quick overview of Bayesian inference and probabilistic
programming in general, necessary to understand the requirements and usual approaches of
probabilistic programming systems.  Consequently, the machinery and language used to develop the
graph tracking system forming the main part of the work are described.  First, basic notions and
techniques of the Julia compilation process as well as the language's metaprogramming capabilities
are described, which form the basis of the implementation.  Second, a short introduction to graph
tracking and source-to-source automatic differentiation is given, from which many of the ideas and
terminology that will later be used were taken


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bayesian Inference and MCMC methods}
\label{sec:bayes-infer}

Probabilistic modeling \parencite{winn2019modelbased} is an approach to model phenomena based on the
assumption that observable data can be fully described through some generative process that involves
randomness.  Recovering the details of this process, by estimating which one from a class of
processes fits observed data best, is a form of learning: if we have a good description of how
observations are generated, we can make summary statements about the whole population (descriptive
statistics) or predictions about new observations.  For example, learning the specifics a
conditional relation between independently observed paired data can be used to solve regression or
classification problems.

Within the Bayesian framework
\parencite{bolstad2004introduction,congdon2006bayesian,gelman2020bayesian}, we assume that the
generative process is specified by random variables related through conditional distributions with
densities, which describe how the observables would be generated: some \emph{latent variables} are
generated from \emph{prior distributions}, and the data are generated conditionally on the latent
variables.  The goal is to learn the \emph{posterior distribution} of the latent variables given the
data.  Whereas the generative model specifies how we assume data generation to work from latent to
observed values in \enquote{forward} direction, the posterior estimate allows us to reason
\enquote{backwards} from given observations to the latent values that have generated them.  This can
also be described iteratively, as a process of updating prior beliefs through the inclusion of new
knowledge given by observations.

As an example, consider a linear regression model, where some output depends linearly on an input
variable, with Gaussian noise:
\begin{equation}
  \label{eq:bayes-regression-model}
  Y \sim \Normal(\theta_0 + x\theta_1, \sigma). 
\end{equation}
In a traditional approach, \(\theta\) would be considered fixed, and estimated through least-squares
optimization given pairs of observations of \(x\) and \(y\).  In a Baysian approach, though, we
first decide on some prior distribution for the parameters, which are now a thought of as
realizations of random variable \(\Theta\), and then try to recover the posterior distribution of
\(\Theta\) given the observed data.  This estimate allows some more applications, compared to the
single point estimate of least-squares regression.  With the full posterior distribution, more
complex question can be answered, such as the variance or credibility of the estimation.  We can
also derive a posterior predictive distribution, that models the probability of future values,
taking into account the information gained by the values and variation of the already observed
values \parencite{marin2007bayesian}.

\newthought{In the following}, we will mostly assume that the involved random variables have
densities with respect to a suitable base measure, generally written as \(\mu\): the counting
measure in the discrete case, and the Lebesgue measure in the finite-dimensional continuous case
\parencite{kallenberg2006foundations}.  This allows to conveniently unify summation and integration
under one notation.  See appendix~\ref{sec:measure-theory} for more information.

The posterior of the generative model can be expressed as a conditional distribution using Bayes'
theorem. In terms of densities, we then have\footnote{Note the abuse of notation regarding
  \(\prob{\cdot}\); see page~\pageref{cha:notation} on notation.}
\begin{equation}
  \label{eq:bayes}
  \overbrace{\prob{\theta \given x}}^{\text{posterior}} =
  \frac{\overbrace{\prob{x \given \theta}}^{\text{likelihood}}\;
    \overbrace{\prob{\theta}}^{\text{prior}}}{\prob{x}},
\end{equation}
where \(x\) are the observed data, and \(\theta\) are the latent values. The posterior represents
the distribution of the unobserved variables as a combination of the prior belief updated by what
has been observed~\parencite{congdon2006bayesian}.  \(\theta\) often functions as a parametrization
of the likelihood distribution.  Also note that in practice, one might not be interested in all of
the latent variables, but only a marginal; this corresponds to integrating out some parts of
\(\theta\).

Going beyond simple applications like the example mentioned above, hand\-ling the posterior gets
difficult, though.  Simply evaluating the posterior density
\(\theta \mapsto \prob{\theta \given x}\) at single points is not enough in a Bayesian setting for
usages such as prediction, certain parameter estimation methods, or exact evaluation of the
normalization term \(\prob{x}\).  The problem is that almost all of the relevant quantities depend
on some sort of expectation over the posterior, an integral of the form
\begin{equation}
  \label{eq:posterior-expectation}
  \Exp{f(\Theta) \given X = x} = \int f(\theta) \prob{\theta \given x} \dif \mu(\theta),
\end{equation}
for some (measurable) function \(f\) (the integral is understood to range over the whole support of
\(\Theta\)). This in turn involves calculating the marginal
\begin{equation}
  \label{eq:normalizing}
  \prob{x} = \int \prob{x, \theta} \dif \mu(\theta),
\end{equation}
the normalization term in equation~\eqref{eq:bayes}, often called the \enquote{model evidence}.

When the involved distributions are of a sufficiently \enquote{nice} form, e.g., a conjugate pair
\parencites[see][chapter 2.2.2]{marin2007bayesian}[chapter 9.2.5]{murphy2012machine}, the
integration can be performed analytically, since the posterior density has a closed form for a
certain known distribution, or at least is a known integral.  In general, however, this is not
tractable, not even by standard numerical integration methods, and approximations have to be made.
Even for discrete variables, naive application of summation can lead to combinatorial explosion.

\newthought{Different techni{q}ues} for posterior approximation are available: among them are
optimization-based approaches for general graphical models, such as variational inference
\parencite[chapter 21 and 22]{murphy2012machine} and other methods generalized under the framework
of message passing \parencite{minka2005divergence}.  The methods described in this thesis, however,
fall into the category of Monte Carlo methods, and are based on sampling \parencites[chapter
23]{murphy2012machine}{vihola2020lectures}.  Their fundamental idea is to derive, for given
observations \(x\) and a specified density of \(\Theta \from \pi(\cdot \given x)\), a sampling
procedure with a consistent estimator for expectations:
\begin{equation}
  \label{eq:mc-methods}
  \kth{I}(f) \to \Exp{f(\Theta) | X = x} = \int f(\theta) \pi(\theta \given x) \dif\mu(\theta), \quad \text{as} \quad k
  \to \infty
\end{equation}
in some appropriate stochastic convergence (usually convergence in probability is enough).

Examples of such methods are rejection sampling \parencites[chapter
II.3]{devroye1986nonuniform}[section 4]{vihola2020lectures}, importance sampling \parencite[section
4]{vihola2020lectures}, and particle filters \parencite{dahlin2015getting}.  Many Monte Carlo
methods are defined in a form that directly samples a sequence of individual random variables
\(\sequence{\kth{Y}}\), called a \emph{chain}, for which the estimator is given by the arithmetic
mean, such that a law of large numbers (LLN) holds:
\begin{equation}
  \label{eq:mc-lln}
  \kth{I}(f) = \frac{1}{k} \sum_{i=1}^{k} f(\kth[i]{Y}) \to \Exp{f(\Theta) \given X = x}
\end{equation}
If we can sample \(\kth{Y} \from \pi(\cdot \given x)\) exactly, they are \iid{} and the LLN holds
trivially; such samplers exist, but might also be difficult to derive or not possess good enough
convergence properties (especially in high dimensions).  Another large class of samplers is formed
by \emph{Markov Chain Monte Carlo} (MCMC) methods \parencite{vihola2020lectures,robert1999monte},
which, instead of sampling exactly from the density, define \(\kth{Y}\) via a (time-homogeneous)
Markov chain:
\begin{equation}
  \label{eq:mc-kernel}
  \begin{aligned}
    &\Prob{\kth[k+1]{Y} \in \dif y
      \given \kth{Y} = \kth{y}, \ldots, \kth[1]{Y} = \kth[1]{y}} \\
    &\quad = \Prob{\kth[k+1]{Y} \in \dif y \given \kth{Y} = \kth{y}}  \\
    &\quad = K(\kth{y}, \dif y) \\
    % &\quad = k(y \given \kth{y}) \dif\mu(y)
  \end{aligned}
\end{equation}
for all \(k \ge 1\).  By constructing the parameterized measure \(K\), the \emph{transition kernel},
in the right way, the resulting has target density \(\pi(\cdot \given x)\) as the unique stationary
distribution~-- that means for all \(\pi(\cdot \given x)\)-measurable sets \(A\),
\begin{equation}
  \label{eq:stationarity}
  \int \pi(\theta \given x) K(\theta, A) \dif\mu(\theta) = \int_A \pi(\theta \given x) \dif\mu(\theta) =
  \Prob{\Theta \in A \given X = x},
\end{equation}
and the LLN for Markov chains holds.  (For discrete spaces, this relation is more familiarly written
as a left eigen-problem on a stochastic matrix: \(\pi K = \pi\) for \(x\) fixed, and \(\pi\) and
\(K\) considered a vector and matrix.)  The advantage of MCMC methods is that they apply equally
well to many structurally complex models, and treat densities in a uniform way, without requiring
special knowledge about the specific distribution in question.  I refer to \textcites[chapter
6]{vihola2020lectures}{robert1999monte}[chapters 24 and following]{murphy2012machine} as
introductions to MCMC theory and practice.

\newthought{Fre{q}uently, MCMC methods} are variations of the \emph{Metropolis-Hastings algorithm}
(MH), which splits the general definition of the transition kernel into two parts: a proposal
distribution, given by a transition kernel
\((\kth[k-1]{y}, \kth{y}) \mapsto q(\kth[k-1]{y}, \kth{y})\) which is easy to sample from, and an
acceptance rate function \(\alpha\).  Subsequent samples are then produced by proposing values from
the conditional distribution \(q(\kth[k-1]{y}, \cdot)\) dependent on previous chain element
\(\kth[k-1]{y}\), and incorporating them into the chain with a probability given through \(\alpha\)
(see algorithm~\ref{alg:mh}).  There exist many MH-based schemes with different properties and
requirements: from the classical random-walk Metropolis algorithm with Gaussian proposals, over
Reversible Jump MCMC for varying dimensions \parencite{green1995reversible}, to gradient-informed
methods like Metropolis Adjusted Langevin and Hamiltonian Monte Carlo (HMC)
\parencite{betancourt2018conceptual,girolami2011riemann}.

% \begin{algorithm}[t]
%   \sffamily
%   \hrule
%   \begin{enumerate}
%     \firmlist
%   \item Start from an arbitrary \(\kth[1]{Y} = \kth[1]{y}\) with \(\pi(\kth{y}) > 0\).
%   \item For each \(k \ge 1\):
%     \begin{enumerate}
%       \firmlist
%     \item Sample a proposal \(\kth[k]{\hat{Y}} \from q(\kth[k-1]{Y}, \cdot)\).
%     \item With probability \(\alpha(\kth[k]{\hat{Y}}, \kth[k-1]{Y})\), set
%       \(\kth[k]{Y} = \kth[k]{\hat{Y}}\); else, keep \(\kth[k]{Y} = \kth[k-1]{Y}\).
%     \end{enumerate}
%   \end{enumerate}
%   \hrule
%   \caption{General scheme for the Metropolis-Hastings algorithm.\label{alg:mh}}
% \end{algorithm}

\begin{algorithm}[t]
  \hrule
  \begin{algorithmic}
    \State Start from an arbitrary \(\kth[1]{Y} = \kth[1]{y}\) with \(\pi(\kth{y}) > 0\)
    \For{\(k \ge 1\)}
    \State Sample a proposal \(\kth[k]{\hat{Y}} \from q(\kth[k-1]{Y}, \cdot)\)
    \State With probability \(\alpha(\kth[k]{\hat{Y}}, \kth[k-1]{Y})\), set
    \(\kth[k]{Y} = \kth[k]{\hat{Y}}\); else, keep \(\kth[k]{Y} = \kth[k-1]{Y}\)
    \EndFor
  \end{algorithmic}
  \hrule
  \caption{General scheme for the Metropolis-Hastings algorithm.\label{alg:mh}}
\end{algorithm}

For multi-component structures, where the latent variables have a blocked form
\(\Theta = [\Theta_1, \ldots, \Theta_M]\), a good proposal distribution can be hard to find, though.
One way to break down the problem is to use a family of block-wise updates, given by conditional
kernels \(q_{i}\) operating only on the single block \(\Theta_i\), with the rest, \(\Theta_{-i}\),
fixed.  Then we can use the following modified proposal \(\hat{Y}\) in algorithm~\ref{alg:mh},
\begin{equation}
  \label{eq:conditional-kernels}
  \begin{aligned}
    \kth[k]{\hat{Y}}_{-i} &= \kth[k-1]{Y}_{-i}, \\
    \kth[k]{\hat{Y}}_{i} &\from q_{i}(\kth[k-1]{Y}_{i}, \cdot \given \kth[k-1]{Y}_{-i})
  \end{aligned}
\end{equation}
(negative indices denote removal of the indicated entry).  The blocks can be scalar or multivariate,
the kernels may themselves be any valid transition kernel, and the sampling order of the blocks
(\(i\)) can be chosen in different random or determinstic ways under some technical conditions
\parencite[chapter 6.6]{vihola2020lectures}.  This allows one to freely mix different MCMC methods
suitable for each variable in a problem.

This so-called \enquote{within-Gibbs} sampler bears its name because it is a generalization of the
classical \emph{Gibbs sampling} algorithm \parencite{geman1984stochastic}, using as a simple set of
transition kernels the conditional distributions of the parameters \(\Theta\):
\begin{equation}
  \label{eq:gibbs-conditional-kernel}
  q_{i}(\kth[k-1]{y}_{i}, \dif \kth{y}_{i} \given \kth[k-1]{y}_{-i}) =
  \Prob{\kth{\Theta}_{i} \in \dif\kth{y}_{i} \given \kth[k-1]{\Theta}_{-i} = \kth[k-1]{y}_{-i}, X = x}
\end{equation}
(notably independent of the previous \(\kth[k-1]{y}_{i}\)).  They can directly be used as component
proposals for a within-Gibbs sampler, leading to a canceling acceptance rate of \(\alpha \equiv 1\).
This approach has the advantage of being very algorithmic, which makes it rather easy to apply, even
by hand, to many models.  Hence, the method is a popular starting point for general probabilistic
programming systems, most prominently BUGS \parencite{lunn2000winbugs,lunn2009bugs} and JAGS
\parencite{plummer2003jags,plummer2017jags}.

In many real-world models, the factorization structure is quite sparse and results in small Markov
blankets.  Algorithms to derive Gibbs samplers exploit this large independency between variables.
In short, they \enquote{trim} the dependency graph of the model to the local Markov blankets of each
target variable, and derive either a full conditional from it, where possible (for discrete or
conjugate variables), or otherwise approximate it through appropriate local sampling (e.g., slice
sampling) \parencite[see][]{plummer2003jags}.

As an example, consider a simple Gaussian mixture model with equal weights, specified as follows:
\begin{equation}
  \label{eq:normal-mixture-1}
  \begin{aligned}
    \mu_{k} &\from \Normal(m, s) \quad\text{for } 1 \le k \le K, \\
    Z_{n} &\from \distr{Categorical}(K) \quad\text{for } 1 \le n \le N, \\
    X_{n} &\from \Normal(\mu_{Z_{n}}, \sigma) \quad\text{for } 1 \le n \le N.
  \end{aligned}
\end{equation}
(\(\distr{Categorical}(K)\) is short for a uniform categorical distribution with probabilities
\(1/K, \ldots, 1/K)\).)  To derive the conditional distribution of \(Z_{n}\) given the remaining
variables, we start by writing down the factorization of the joint density:
\begin{equation}
  p(z_{1:N}, \mu_{1:K}, x_{1:N}) = \prod_{k} p(\mu_{k}) \prod_{n} p(z_{n}) \prod_{n} p(x_{n} | \mu_{z_{n}})
\end{equation}
(with \(v_{1:M}\) denoting the combined vector of all \(v_{i}\)). From this, we can derive an
unnormalized density proportional to the conditional by removing all factors not including the
target variable (which become part of the normalization constant):
\begin{equation}
    p(z_{n} \given z_{-n}, \mu_{1:K}, x_{1:N}) \propto p(z_{n}) p(x_{n} | \mu_{z_{n}})
\end{equation}
This is equivalent to finding the Markov blanket of \(Z_{n}\): only those conditionals relating the
target variable to its children and parents remain.  Since the clusters are drawn from a categorical
distribution, the support is discrete, and we can find the normalization constant \(Z\) by
summation:
\begin{equation}
  \setlength{\jot}{0.8\baselineskip}
  \begin{aligned}
    &p(z_{n} \given z_{-n}, \mu_{1:K}, x_{1:N}) = p(z_{n}) p(x_{n} | \mu_{z_{n}}) / Z  \\
    &\quad = \dfrac{\distr{Categorical}(z_{n} \given K) \, \Normal(x_{n} \given \mu_{z_{n}}, \sigma)}{
      \sum_{k \in\, \supp(Z_{n})} \distr{Categorical}(k \given K)\, \Normal(x_{n} \given \mu_{k},
      \sigma)}, \\
    % &\quad = \dfrac{\distr{Categorical}(z_{n} \given K) \, \Normal(x_{n} \given \mu_{z_{n}}, \sigma)}{
    %   \sum_{k = 1}^{K} \distr{Categorical}(k \given K)\, \Normal(x_{n} \given \mu_{k}, \sigma)},
  \end{aligned}
\end{equation}
which can be expressed as a general discrete distribution over \(\supp(Z_{n}) = \{1, \ldots, K\}\),
with the unnormalized weights given by the numerator.  Next, the conditionals of the \(\mu_{k}\)
have the form
\begin{equation}
  \setlength{\jot}{0.8\baselineskip}
  \begin{aligned}
    &p(\mu_{k} \given z_{1:N}, \mu_{-k}, x_{1:N}) \\
    &\quad \propto p(\mu_k) \prod_{n} p(x_{n} | \mu_{k})^{\indicator{z_{n} \, = \, k}} \\
    &\quad = \prod_{n} \left( \Normal(\mu_{k} \given m, s) \,
      \Normal(x_{n} \given \mu_{k}, \sigma) \right)^{\indicator{z_{n} \, = \, k}}
  \end{aligned}
\end{equation}
which we recognize as a product of conjugate pairs of normal distributions (\(\vvmathbb{1}\) being the
indicator function).  More examples are extensively covered in \textcite[chapter
24.2]{murphy2012machine}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Probabilistic Programming}
\label{sec:prob-prog}

\begin{lstfloat}[t]
  \begin{lstlisting}[style=lstfloat]
@model function normal_mixture(x, K, m, s, σ)
    N = length(x)

    μ = Vector{Float64}(undef, K)
    for k = 1:K
        μ[k] ~ Normal(m, s)
    end

    z = Vector{Int}(undef, N)
    for n = 1:N
        z[n] ~ Categorical(K)
    end

    for n = 1:N
        x[n] ~ Normal(μ[z[n]], σ)
    end

    return x
end
\end{lstlisting}
    \caption{\turingjl{} implementation of a Gaussian mixture model with prior on the cluster centers,
    equal cluster weights, and all other parameters fixed.\label{lst:normal}}
\end{lstfloat}

Probabilistic programming is a structured way for implementing generative models, as described in the
previous section, through the syntax of a programming language.  It is beneficial to consider
probabilistic programs not only as syntactic sugar for denoting the implementation of a joint
probability density over some set of variables, but as organized objects in their own right: they
open up possibilities that \enquote{black box} density functions cannot automatically provide. In
more concise terms of \textcite{vandemeent2018introduction}:
\begin{quote}
  Probabilistic programming is largely about designing languages, interpreters, and compilers that
  translate inference problems denoted in programming language syntax into formal mathematical
  objects that allow and accommodate generic probabilistic inference, particularly Bayesian
  inference and conditioning.
\end{quote}

A probabilistic program differs from a regular program (that may also contain stochastic parts)
through the possibility of being conditioned on: some of the internal variables can be fixed to
observed values, from outside. As such, the program denotes on the one hand a joint distribution,
that can be \emph{forward sampled} from by simply running the program top to bottom and producing
(pseudo-) random values.  But at the same time, it also represents a conditional distribution, in
form on the unnormalized conditional density, which together with an inference algorithm can also be
\emph{backward sampled} from.  (Other terms, such as \enquote{evaluation} and \enquote{querying},
are used as well.)  Consider the model~\eqref{eq:normal-mixture-1} from above: to perform inference
on it in \turingjl{} \parencite{ge2018turing}, the probabilistic programming language used in this
thesis, its mathematical description might be translated into the Julia program given in
listing~\ref{lst:normal}.

We can then sample from the model in several ways using Julia:
\begin{lstlisting}
julia> m = normal_mixture(x_observations, K, m, s, σ);
julia> forward = sample(m, Prior(), 10);
julia> chain = sample(m, MH(), 1000);
\end{lstlisting}
A model instance \jlinl{m} is created first.  The value of \jlinl{forward} will then be a
dataframe-like object containing 10 values for each variable sampled from the forward (i.e., joint)
distribution, matching the size of \jlinl{x_observations}.  Similarly, \jlinl{chain} will contain a
length 1000 sample from a Markov chain targeting the posterior, conditionally on
\jlinl{x_observations}, created using the MH algorithm.  If we were to write out code for these two
functionalities manually, in idiomatic Julia, we would end up with at least two separate functions
needed for the sampler:
\begin{lstlisting}
function normal_mixture_sampler(N, K, m, s, σ)
    μ = rand(Normal(m, s), K)
    z = rand(Categorical(K), N)
    x = rand.(Normal.(μ[z], s))
    return μ, z, x
end

function normal_mixture_logpdf(μ, z, x, K, m, s, σ)
    N = length(x)
    ℓ = 0.0
    ℓ += sum(logpdf(Normal(m, s), μ[k]) for k = 1:K)
    ℓ += sum(logpdf(Categorical(K), z[n]) for n = 1:N)
    ℓ += sum(logpdf(Normal(μ[z[n]]), x[n]) for n = 1:N)
    return ℓ
end
\end{lstlisting}
And still, with these, we would lack much of the flexibility of models written in a dedicated
library such as\turingjl: no general interface for sampling algorithms to automatically detect all
latent and observed variables; no possibility for other, nonstandard execution forms as are needed
for variational inference or gradient computation for HMC; no automatic name extraction and
dataframe building for chains.  All these points highlight the advantages of dedicated probabilistic
programming languages (PPLs) over hand-written model code.  (Additionally, there is of course a
benefit of reducing errors introduced by the sampling function not matching the likelihood function,
or errors involving log-probabilities.)

\newthought{Many PPLs are implemented} as external domain-specific languages (DSLs), like Stan
\parencite{carpenter2017stan}, JAGS \parencite{plummer2003jags}, and BUGS
\parencite{lunn2000winbugs,lunn2009bugs}.  Others are specified in the \enquote{meta-syntax} of Lisp
S-expressions, as Church \parencite{goodman2012church}, Anglican \parencite{wood2015new}, or Venture
\parencite{mansinghka2014venture}.  A third group is embedded into host programming languages with
sufficient syntactic flexibility, for example \juliapackage{Gen.jl}
\parencite{cusumano-towner2019gen,cusumano-towner2020gen} and \juliapackage{Soss.jl}
\parencite{scherrer2019soss} in Julia (besides the already named \turingjl{}), or Pyro
\parencite{bingham2018pyro} and PyMC3 \parencite{salvatier2016probabilistic} in Python.

The latter approach is advantageous when one wants to enable the use of regular, general-purpose
programming constructs or interact with other functionalities of the host language.  There are also
a variety of further reasons why one would rather describe an inference problem in terms of a
program than in more \enquote{low-level} form, e.g., as a graph or likelihood function.  In a good
probabilistic programming DSL, models should be expressible very concisely and intuitively, without
much bookkeeping (e.g., as close to textbook model specifications as possible).  At the same time,
structures should exist to allow complex behaviour, such as to
\begin{itemize}
  % \firmlist
\item define recursive relationships,
\item write models using imperative constructs, such as loops, or mutable intermediate computations
  for efficiency,
\item optimize details of the execution, e.g. for memoization, likelihood scaling, or preliminary
  termination,
\item use distributions over complex custom data structures, e.g. trees,
\item perform inference involving complex transformations from other domains, for which
  implementations already exist, e.g. neural networks or differential equation solver, or
\item integrate calls to very complex external systems, e.g. simulators or renderers.
\end{itemize}
Depending how many of these features should be supported, several possibilities for the
implementation of such a DSL exist.  All are based on some form of abstract interpretation.  A rough
distinction can be made between \emph{compilation-based methods}, which statically translate the
model code to a graph or density function, and \emph{evaluation-based methods}, which dynamically or
implicitly build such a structure at run-time, by allowing an inference algorithm to interleave the
execution.  The latter makes it easier to include host-language control constructs.  See
\textcite{vandemeent2018introduction} for a general introduction into some common implementation
approaches for PPLs, and \textcite{goodman2014design} for a detailed overview of the internals of
one specific, continuation-based implementation called WebPPL (using a Lisp-based syntax).

\begin{lstfloat}
  \begin{lstlisting}[style=lstfloat]
function normal_mixture(x, K, m, s, σ)
    function evaluator(rng, model, varinfo, sampler, context, x, K, m, s, σ)
        N = length(x)
        μ = Vector{Float64}(undef, K)
        for k = 1:K
            dist_mu = Normal(m, s)
            vn_mu = @varname μ[k]
            inds_mu = ((k,),)
            μ[k] = tilde_assume(
                rng, context, sampler, dist_mu, vn_mu, inds_mu, varinfo
            )
        end
        z = Vector{Int}(undef, N)
        for n = 1:N
            dist_z = Categorical(K)
            vn_z = @varname z[n]
            inds_z = ((n,),)
            z[n] = tilde_assume(
                rng, context, sampler, dist_z, vn_z, inds_z, varinfo
            )
        end
        for n = 1:N
            dist_x = Normal(μ[z[n]], σ)
            vn_x = @varname(x[n])
            inds_x = ((n,),)
            if isassumption(model, x, vn_x)
                x[n] = tilde_assume(
                    rng, context, sampler, dist_x, vn_x, inds_x, varinfo
                )
            else
                tilde_observe(
                    context, sampler, dist_x, x[n], vn_x, inds_x, varinfo
                )
            end
        end
        return x
    end
    return Model(
        :normal_mixture, evaluator, 
        (x = x, K = K, m = m, s = s, σ = σ), 
        NamedTuple()
    )
end
\end{lstlisting}
  \caption{Slightly simplified macro-expanded code of the model in listing~\ref{lst:normal}.  The
    inner code is put into an \protect\jlinl{evaluator} closure, and every tilde statement is
    replaced by a \protect\jlinl{tilde_*} function, to which additional data and state information
    are passed.\label{lst:normal-expanded}}
\end{lstfloat}
\setlength{\parskip}{0pt}

\newthought{Models in \turingjl{}} are written in \dppljl{} syntax \parencite{tarek2020dynamicppl},
which transforms valid Julia function definitions into a reusable representation (\jlinl{@model} is
a Julia macro; see section~\ref{sec:comp-metapr-julia} for more explanation).  The result is a new
function which produces instances of a structure of type \jlinl{Model}, which in turn will contain
the provided data, some metadata, and a nested function with the slightly changed original model
code. In the concrete case of the model in listing~\ref{lst:normal}, the resulting code would be
approximately equal to the code in listing~\ref{lst:normal-expanded}.  The purpose of this is the
following: the outer function, the \enquote{generator}, constructs an instance of the model for
given parameters~-- usually done once per inference problem, to fix the observations and
hyper-parameters.  Subsequently, the \jlinl{sample} function can be applied to this instance with
different values for the sampling algorithm, which in turn will use the \jlinl{evaluator} function
of the instance to run the model with chosen \jlinl{sampler} and \jlinl{context} arguments, that are
passed to the \enquote{tilde functions}, to which the statements of the form \jlinl{expr ~ D} are
converted.

A special distinction is made for the tilde functions of variables that are based on the model's
arguments. \dppljl{} distinguishes between \emph{assumptions}, i.e., latent variables that should be
recovered through posterior inference, and \emph{observations}, that need to be provided when
instantiating the model and are conditioned upon.  The latter by default will only contribute to the
likelihood, instead of being sampled.  But in certain cases, such as in probability evaluation or
when using the complete model in a generative way, this behavior can be different.  For this
purpose, the tilde functions for the variables \jlinl{x[i]} in listing~\ref{lst:normal-expanded} are
differentiated in a conditional statement.

Inside the tilde functions, the real stochastic work happens.  Depending on the \jlinl{sampler} and
the \jlinl{context}, values may be generated and stored in the \jlinl{VarInfo} object, and the joint
log-likelihood incremented, as happens for most MCMC samplers.  In this case, one call to the
\jlinl{evaluator} corresponds to one sampling step.  In other situations, model evaluation serves
the purpose of density evaluation, in which no new values need to be produced; this use case is
needed for probability queries, or density-based algorithms (which might additionally use automatic
differentiation on the density evaluation procedure).  All shared information for external usage is
thereby conventionally stored in the \jlinl{VarInfo} object, which resembles a dictionary from
variable names\footnote{These \texttt{VarName} objects, constructed by the macro \texttt{@varname},
  simply represent an indexed variable through a symbol and a tuple of integers.}  to values
(internal sampler state can also be stored in the \jlinl{sampler} object).  Through the
\jlinl{sample} interface, the resulting values are then stored in a \jlinl{Chains} object, a data
frame containing a value for each variable at each sampling step.

From the point of view of a sampling algorithm, all that it sees is a sequence of tilde statements,
consisting of a value, a variable name, and a distribution.  \turingjl{}, crucially, does not have a
representation of model structure.  This is sufficient for many kinds of inference algorithms that
it already implements~-- Metropolis-Hastings, several particle methods, HMC and NUTS, and
within-Gibbs combinations of these~-- but does not allow more intelligent usage of the available
information.  For example, to use a true, conditional, Gibbs sampler, the user has to calculate the
conditionals themselves.  Structure-based optimizations such as partial specialization of a model to
save calculations, automatic conjugacy detection \parencite{hoffman2018autoconj}, or model
transformations such as Rao-Blackwellization \parencite{murray2017delayed} cannot be performed in
this representation.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Compilation and Metaprogramming in Julia}
\label{sec:comp-metapr-julia}

To better explain the inner workings of \turingjl{} models and the program transformations
introduced later, we will now turn to an overview of Julia's evaluation, compilation, and
metaprogramming techniques.

Julia \parencite{bezanson2017julia} is a programming language with a strong, dynamic type system
with nominal, parametric subtyping and elaborate multiple dispatch.  It uses LLVM
\parencite{llvmproject2019llvm} for JIT-compilation and while it is dynamically typed, a combination
of method specialization and type inference allows it to produce very optimized, fast machine code
\parencite{bezanson2018julia}.  The language syntactically draws on a certain resemblance to Matlab,
Python, or Ruby.  Contrary to them, it is designed to utilize a compiler, and not primarily rely on
libraries calling foreign functions (e.g., Numpy), to achieve C-like speed.  Although Julia does
use, e.g., BLAS and LAPACK for numerical algebra, there is nothing that fundamentally prevents
implementing their functions: true array types, fast loops, and various optimizations are available,
as opposed to languages like Python, which are fundamentally limited by to their dynamic
interpretation.  This advantage carries over to domains outside of numeric computation, of course.

On top of that, the language is built on a very open compilation model.  Underlying the surface
syntax is an abstract syntax tree (AST), that is used in the initial stages of compilation, but also
exposed to the programmer through macros, which allow to transform pieces of code at compile time.
Julia macros are proper hygienic, LISP-style code transformations \parencite[cf.][]{hoyte2008let},
not simple text-substitutions as C preprocessor macros.  As an example, look at the following
method\footnote{The terminology of Julia uses \emph{function} for a callable object, which can have
  multiple \emph{methods} for different combinations of argument types.  This is what allows
  multiple dispatch: when a function is applied, the types of the arguments are determined, and the
  most specific matching methods selected and called.  For example, the \protect\jlinl{+} function
  has many methods for adding integers, floats, arrays, etc.}  that sums up the \jlinl{sin} values
of a list of numbers:
\begin{lstlisting}
function foo(x)
    y = zero(eltype(x))
    for i in eachindex(x)
        @show y += sin(x[i])
    end
    return y
end
\end{lstlisting}
The invocation of the standard library macro \jlinl{@show} will be treated by the compiler, during
parsing, as a function call receiving as input the following data structure, representing \jlinl{y
  += sin(x[i])} in S-expression-like form:
\begin{lstlisting}
Expr(:(+=), :y, Expr(:call, :sin, Expr(:ref, :x, :i)))
\end{lstlisting}
In this particular case, the nested structure is not taken advantage of or transformed, but simply
converted to a string used to print the value of the expression, labeled by its form in the code:
\begin{lstlisting}
macro show(ex)
    blk = Expr(:block)
    unquoted = sprint(Base.show_unquoted, ex) * " = "
    assignment = Expr(:call, :repr, Expr(:(=), :value, esc(ex)))
    push!(blk.args, Expr(:call, :println, unquoted, assignment))
    push!(blk.args, :value)
    return blk
end
\end{lstlisting}
The result is then spliced back into the AST, which is compiled further as if it were written as
\begin{lstlisting}
function foo(x)
    y = zero(eltype(x))
    for i = eachindex(x)
        begin
            println("y += sin(x[i]) = ", repr(var"#1#value" = (y += sin(x[i]))))
            var"#1#value"
        end
    end
    return y
end
\end{lstlisting}
(Note the automatic conversion of the symbol \jlinl{:value} to a generated name \jlinl{#1#value}, in
order to not possibly shadow any variables from the calling scope.)


\begin{lstfloat}[t]
\begin{lstlisting}[style=lstfloat]
1: (%1::Core.Compiler.Const(foo, false), %2::Array{Float64,1})
  %3 = eltype(%2)::Compiler.Const(Float64, false)
  %4 = zero(%3)::Float64
  %5 = eachindex(%2)::Base.OneTo{Int64}
  %6 = iterate(%5):Union{Nothing, Tuple{Int64,Int64}}
  %7 = (%6 === nothing)::Bool
  %8 = not_int(%7)::Bool
  br §3 (%4) unless %8
  br §2 (%6, %4)
2: (%9, %10)
  %11 = getfield(%9, 1)::Int64
  %12 = getfield(%9, 2)::Int64
  %13 = getindex(%2, %11)::Float64
  %14 = sin(%13)::Float64
  %15 = (%10 + %14)::Float64
  %16 = repr(%15)::String
  %17 = println("y += sin(x[i]) = ", %16)
  %18 = iterate(%5, %12)::Union{Nothing, Tuple{Int64,Int64}}
  %19 = (%18 === nothing)::Bool
  %20 = not_int(%19)::Bool
  br §3 (%15) unless %20
  br §2 (%18, %15)
3: (%21)
  return %21
\end{lstlisting}
  \caption{SSA-form of the lowered form of the method \protect\jlinl{foo(::Vector\{Float64\})} as
    defined defined above, annotated with inferred types (as through
    \texttt{@code\_warntype}).\label{lst:foo-inferred}}
\end{lstfloat}

After macro expansion, the code of the method is \emph{lowered} into an intermediate
representation consisting of only function calls and branches.  This comprises of several
transformations: for one, certain syntactic constructs are \enquote{desugared} into primitive
function calls.  For example, array accesses, \jlinl{x[i]}, are replaced by calls to the library
function \jlinl{getindex(x, i)}.  The for loop in the example is converted into a while loop using
the \jlinl{iterate} library function:
\begin{lstlisting}
iterable = eachindex(x)
iter_result = iterate(iterable)
while !(iter_result === nothing)
    i, state = iter
    @show y += sin(x[i])
    iter_result = iterate(iterable, state)
end
\end{lstlisting}
Consequently, all nested expressions are split apart, so that only simple, unnested calls remain,
and any subsequent assignments to variables are linearized to a series of definitions, with newly
introduced names of the form \jlinl{\%i}.  The remaining control flow statements (e.g., while loops
and conditionals) are represented through a sequence of labeled \emph{basic blocks}, with (possibly
conditional) branches between them (with return statements forming a special kind of branch without
a block target).  The sequence of assignments is further processed into \emph{single static
  assignment (SSA) form} \parencite{rosen1988global,singer2018static}, the characteristic property
of which is that every variable is assigned exactly once, by giving a unique, position-independent
name to each intermediate value of an expression.  By introducing this immutability guarantee and
flattened structure, the resulting code is, in a certain sense, referentially transparent, which
facilitates program flow analyses, and makes many transformations easier
\parencite{muchnick1997advanced}.  Accordingly, SSA form is widely used in intermediate forms of
compiler systems (such as LLVM \parencite{llvmproject2019llvm}, or Swift
\parencite{apple2020swifta}), simplifying transformations and optimizations.

The result of the translation of our example into three basic blocks can be found in
listing~\ref{lst:foo-inferred}: the first block contains the logic before the \texttt{for}-loop,
including the test condition and the desugared \jlinl{iterate} primitive.  In the second block, we
see the lowered form of array indexing with \jlinl{getindex}, and the logic that the \jlinl{@show}
macro was expanded to.  The block has two block arguments, \jlinl{\%9} and \jlinl{\%10}, which are
used to pass forward the updated iteration state \jlinl{\%18} and incremented value \jlinl{\%15}.
The branches are the same as in the first block.  Finally, the third block is used to break out of
the loop; it receives the final summed up value and returns it.

There is one notable complication regarding conversion to SSA form: we need to be able to
distinguish between assignments of variables arising from \enquote{joined} control flow paths.
Consider the assignment of \jlinl{y} in the following code example:
\begin{lstlisting}
x = f()
if !g()
    y = x - 1
else
    y = x + 1
end
h(y)
\end{lstlisting}
Here, the value of \jlinl{h(y)} depends on two possible locations of \jlinl{y}~-- hence, we cannot
simply rename every variable in a naive way.  Instead, in the variant of SSA form used in this text
and most of Julia, values of variables that are assigned in multiple parent blocks are passed on as
\emph{block arguments}, as in figure~\ref{fig:ssa-phi} on the right, and subsequently in this work.
This makes basic blocks resemble local functions, and cleanly resolves the problem of joins just
like functions handle variable inputs.  The traditional, functionally equivalent alternative is to
introduce \emph{\(\phi\)-functions} \parencite{rosen1988global}, which are defined ad-hoc to
distinguish between several values depending on the control path taken before.  This form is shown
in the same figure on the left.

\begin{figure}[t]
  \centering
  \hfill
  \subbottom{\includegraphics[width=0.4\textwidth]{figures/ssa-phi}}
  \hfill
  \subbottom{\includegraphics[width=0.4\textwidth]{figures/ssa-args}}
  \hfill\null
  \caption{Two control flow graphs of the same function, illustrating the correspondence between SSA
    representations using \(\phi\)-functions and block arguments.  The SSA variables
    \protect\jlinl{\%3} and \protect\jlinl{\%4} correspond to the values of \protect\jlinl{y} in the
    two branches, which are merged in \protect\jlinl{\%5}.}
  \label{fig:ssa-phi}
\end{figure}

In the next step, type inference is applied.  Until now, the operations involved were purely
syntactic in nature, and could be performed by solely transforming the code of the function
\jlinl{foo}, without taking into account semantic information.  As soon as \jlinl{foo} is called on
a concrete type during evaluation, though, a specific overload, called a \emph{method}, must be
chosen.  To apply type inference on the body of a given function, the most specific method fitting
to the argument types of each call will be selecte.  If we go with the example and and consider
\jlinl{foo([1.0])}, with \jlinl{Vector\{Int\}} as the sole argument type, the types as annotated in
listing~\ref{lst:foo-inferred} will be inferred.

\begin{lstfloat}[p]
  \begin{lstlisting}[style=lstfloat]
1 ── %1  = arraysize(x, 1)::Int64
│    %2  = slt_int(%1, 0)::Bool
│    %3  = ifelse(%2, 0, %1)::Int64
│    %4  = slt_int(%3, 1)::Bool
└───       goto §3 if not %4
2 ──       goto §4
3 ──       goto §4
4 ┄─ %8  = φ (§2 => true, §3 => false)::Bool
│    %9  = φ (§3 => 1)::Int64
│    %10 = φ (§3 => 1)::Int64
│    %11 = not_int(%8)::Bool
└───       goto §22 if not %11
5 ┄─ %13 = φ (§4 => 0.0, §21 => %18)::Float64
│    %14 = φ (§4 => %9, §21 => %42)::Int64
│    %15 = φ (§4 => %10, §21 => %43)::Int64
│    %16 = arrayref(true, x, %14)::Float64
│    %17 = invoke sin(%16::Float64)::Float64
│    %18 = add_float(%13, %17)::Float64
│    %19 = sle_int(1, 1)::Bool
└───       goto §7 if not %19
6 ── %21 = sle_int(1, 0)::Bool
└───       goto §8
7 ──       nothing::Nothing
8 ┄─ %24 = φ (§6 => %21, §7 => false)::Bool
└───       goto §10 if not %24
9 ──       invoke getindex(()::Tuple, 1::Int64)::Union{}
└───       $(Expr(:unreachable))::Union{}
10 ┄       goto §11
11 ─       goto §12
12 ─       goto §13
13 ─       goto §14
14 ─ %32 = invoke :(var"#sprint#339")(
             nothing::Nothing, 0::Int64, sprint::typeof(sprint), 
             show::Function, %18::Float64
           )::String
└───       goto §15
15 ─       goto §16
16 ─       goto §17
17 ─       invoke println("y += sin(x[i]) = "::String, %32::String)::Any
│    %37 = (%15 === %3)::Bool
└───       goto §19 if not %37
18 ─       goto §20
19 ─ %40 = add_int(%15, 1)::Int64
└───       goto §20
20 ┄ %42 = φ (§19 => %40)::Int64
│    %43 = φ (§19 => %40)::Int64
│    %44 = φ (§18 => true, §19 => false)::Bool
│    %45 = not_int(%44)::Bool
└───       goto §22 if not %45
21 ─       goto §5
22 ┄ %48 = φ (§20 => %18, §4 => 0.0)::Float64
└───       return %48
\end{lstlisting}
  \caption{Typed and optimized code of the call \protect\jlinl{foo([1.0])} in SSA form, as obtained
    through \protect\jlinl{@code_typed} (the extra bars are due to the formatting of
    \protect\jlinl{CodeInfo}).\label{lst:foo-typed}}
\end{lstfloat}

The last step of compilation happening within Julia consists of inlining and optimizing the typed
intermediate code, resulting in the form shown in listing~\ref{lst:foo-typed}.  Logically, this is
equivalent to \ref{lst:foo-inferred}, but now all function calls are either lowered to intrinsic
functions (\jlinl{arraysize}, \jlinl{sle_int}), or converted to typed \jlinl{invoke} primitives.
Several method calls have been inlined, e.g., the \jlinl{+}, which has become an \jlinl{add_int}
intrinsic.  The many empty blocks and branches, and some spurious constants, are left-overs from the
optimization processes.  This code is in true, traditional SSA form, with all variable slots
eliminated, and block arguments converted to the mentioned \(\phi\)-functions.  Finally, this
representation will be translated and sent to LLVM, where further optimization can happen, and
machine code will be generated and executed, as well as stored for later usage as part of the
just-in-time compilation mechanism.

\newthought{A key principle} in Julia's compilation model is type specialization
\parencite{bezanson2018julia}.  As we have seen, whenever a function call is reached during
evaluation, the concrete types of the arguments are first determined, and then the most specific
method selected.  This automatically gives the language dynamic semantics: a Julia implementation
can theoretically perform type-based dynamic dispatch at every call.  In reality, the Julia compiler
at this point combines multiple dispatch and JIT compilation into one of the main principles of
optimization.  Instead of dynamically evaluating the code of a function at every call, methods are
JIT-compiled the first time they are used.  Their compiled code is then cached in a method table,
which is used for lookup at subsequent calls.  Note that method compilation does not happen
recursively at once: only when the body of a compiled method is actually executed with concrete
arguments, the same process is performed again, for each invoked method.

So, in a sense, JIT compilation can be seen as a function that returns compiled code, given a
function and a tuple of types.  Similar to macros, which transform original code, given an
expression, the process of generating compiled methods from argument types is customizable in Julia:
via so-called \emph{generated functions}.  These are a form of staged programming
\parencite{rompf2010lightweight,bolewski2015staged}, a paradigm in which code generation is
controlled via regular types and functions, instead of specially priviledged ones as macros
are. Such generated functions, when called, are not directly translated into machine code: instead,
they emit new code to the compiler based on the types of their arguments.  The new code is then
JIT-compiled.  For example, when we have two methods of a function \jlinl{f}:
\begin{lstlisting}
f(x::Int) = println("Int")
f(x::String) = println("String")
\end{lstlisting}
we could replace them with the following generated function:
\begin{lstlisting}
@generated function f_generated(x)
    if x == Int
        return :(println("Int"))
    elseif x == String
        return :(println("String"))
    else
        error("Method error")
    end
end
\end{lstlisting}
Calling \jlinl{f_generated(1)} will then determine the argument type (\jlinl{typeof(1) == Int}), and
pass it to the function body of \jlinl{f_generated}.  There, the conditional will select the first
branch, and the expression \jlinl{:(println("Int"))} will be returned.  This is now passed back to
the compiler, which will lower the code and compile the method for \jlinl{Int} arguments, and store
the result in the method table.  The stored code can then be executed~-- on the arguments that were
used to determine the type tuple the generated function has been called with!  The next time
\jlinl{f_generated} is executed, the function body is \emph{not} executed anymore, but the generated
code of the function defined through the expression \jlinl{:(println("Int"))} directly looked
up\footnote{A caveat: technically, the compiler is still free to call the generating code multiple
  times~-- which is the reason generated functions must never involve side effects or depend on
  external state.}.  Of course, simply replacing dispatch, as with this example, is not what
generated functions are used for in practice.  Most applications concern parametric types with
statically known shape arguments, such as tuples, named tuples, or array ranks.  They can also be
used for type-level computations on values that become known only at run-time, through singleton
types such as \jlinl{Val}.

The direct generation of code, given argument types, is however not the furthest we can go.  For
one, generated functions are not only allowed to return \jlinl{Expr} objects~-- the internal
representation of the surface AST~-- but also \jlinl{CodeInfo} objects, which are the internal
representation of lowered code in (almost) SSA form.  This, on its own, would not be of much use
most times, but there is a second, more interesting feature: it is possible to retrieve the lowered
representation of a method programmatically, given a function and an argument type tuple.  Combining
these two, we now have all the tools to implement IR-level code transformations as follows:
\begin{enumerate}
  \firmlist
\item Define a generated function, taking as arguments another function and its arguments.
\item Within this function, obtain the IR of the method of the passed-in function for the remaining
  arguments.
\item Transform this IR however necessary.
\item Return the IR, which will now be compiled and called on the actual arguments.
\end{enumerate}
Importantly, unlike macros, such transformations can be performed \emph{recursively}: one simply
inserts the same generated function to inner function calls during the transformation in step 3.
Since the transformation operates not during parsing, the function to be transformed needs not be
known beforehand, and not be present literally in the code~-- the generated function can be called
on every available callable object, at any time during run-time.  This makes it possible to
transform even functions from other libraries, internally calling yet other functions.  One
particular example of this principle is source-to-source automatic differentiation, as shown in the
next section: a call to a function \jlinl{gradient(f, x, y)} can obtain the IR of the method for
\jlinl{f} on \jlinl{typeof(x)} and \jlinl{typeof(y)}, produce differentiated code, and call the
result on \jlinl{x} and \jlinl{y}.  Naturally, differentiating \jlinl{f} involves recursively
differentiating the other, unknown functions within it, too (down to \enquote{primitive} functions,
whose derivative is known), and combining the results using the chain rule.

This metaprogramming pattern is extremely powerful, and becoming more and more popular.  It allows
to change evaluation semantics in more profound ways than multiple dispatch can: by rewriting the
code of the called function, it is possible to change what invoking a method within its body means.
Through this, several abstract interpretation algorithms can be realized, by extending the existing
data path with additional metadata (such as automatic differentiation, or other forms of information
propagation analysis \parencite[part II]{singer2018static}), or non-standard execution be
implemented (e.g., continuation-passing style transformations).  There exist already two Julia
packages with the goal of simplifying this kind of transformations:
\juliapackage{Cassette.jl}\footnote{\protect\url{https://github.com/jrevels/Cassette.jl}}, which
provides overloadable function application by a so-called \enquote{overdubbing} mechanism,
abstracting out some common patterns; and
\juliapackage{IRTools.jl}\footnote{\protect\url{https://github.com/FluxML/IRTools.jl}}, which has a
more user-friendly alternative to \jlinl{CodeInfo}, and a macro similar to \jlinl{@generated} that
makes writing recursive IR-transformation easier by directly using this data structure.  The latter
is what the work of this thesis builds on.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[Automatic Differentiation and Computation Graphs]{Automatic Differentiation and \newline
  Computation Graphs}
\label{sec:cg-ad}

This section will explain some of the interrelations between automatic differentiation, computation
graphs, and IR transformations, to be able to understand how SSA-form representation is a natural
structure for extracting and analyzing computation graphs, and how the necessary transformations
arise in practice.  To appreciate how the form of the computation graphs interacts with the
mathematics, some foundations need to be introduced first.

\newthought{Many algorithms in machine learning} and other domains can be expressed as optimization
problems over a multivariate function with scalar output~-- typically a loss function over a
parameter space, which measures the performance of a model for a specific task.  The parameters
minimizing the loss function then define the optimal model.  When the loss function is
(sub-)differentiable, there exist a variety of gradient-based optimization methods to minimize the
loss (at least in terms of a practically sufficient local minimum).

While in some cases the loss function is simple enough to find the gradient by hand, in general, the
model, and therefore the loss function, may be specified in terms of rather complicated programs,
for which hand-writing derivatives is difficult to infeasible.  For this reason, computerized
methods for differentiation have been developed.  These can be categorized into three classes:
\begin{itemize}
  \firmlist
\item Finite differences
\item Symbolic differentiation
\item Automatic differentiation
\end{itemize}
In finite differences, the idea is to discretize the definition of derivatives, and numerically
evaluate the function within an environment.  This is simple to implement, but does not scale well
with the dimension of the involved space, and can become numerically unstable in various ways
\parencite[section 5.7]{press2007numerical}.  Symbolic differentiation works through representing
the functions in question as symbolic algebraic objects, and applying the differentiation rules as
one would manually.  This does not lose precision or introduce divergence, but can suffer from
blow-up of the size of the generated expressions; additionally, it requires the functions to be
expressed in a custom representation, different from normal functions or programs
\parencite{baydin2018automatic}.

\newthought{Automatic differentiation} or AD, the third category, is perhaps unfortunately named~--
it does not signify much at first sight.  The relevant idea is to not start from functions as
black-box or symbolic objects, but from programs.  Then the perturbation that makes up the value of
the derivative at a point is propagated through the steps of the program.  For this to work, there
needs to exist an explicit representation of the computation graph at the evaluation at a point,
which is what makes the topic relevant for this thesis.  In contrast to the former two methods, AD
relies on numeric, not symbolic evaluation, but is (up to the floating point errors already present
in the input function) exact~-- no discretization error, as in finite differences, is introduced.
For a more detailed treatment, I refer to \textcite{griewank2008evaluating}, the standard work on
the topic, and the survey by \textcite{baydin2018automatic}, which includes a comparison of
state-of-the-art implementations.

The appendix~\ref{sec:ad-details} contains a more formal introduction of the underlying concepts.  In
short, we treat a program as the composition of functions, and derivatives as equally-shaped
compositions of the linear operators they represent.  Since composition is associative, there are
many possible orders for evaluation of these composed derivatives.  The two main fashions of AD,
\emph{forward mode} and \emph{backward mode}, correspond to evaluation aligning with the original
function evalution order, and its reverse.  These composition orders naturally can be described
through the computation graphs of functions, and transformations on them.  This is illustrated in
figure~\ref{fig:comp-graph}, where we see the computation graph of a simple expression
\jlinl{g(sin(x), y)}, with input variables \jlinl{x} and \jlinl{y} and output \jlinl{Ω}.  There, the
graphs of the corresponding forward-mode (left) and backward-mode (right) calculations are related
to the computation graphs.  The dotted (\(\dot{x}\)) and barred (\(\bar{x}\)) values are the
perturbation values propagated through the derivative graphs, corresponding to intermediate
variables in the original.

\begin{figure}[t]
  \centering
  \subbottom[Forward mode.\label{fig:comp-graph-fw}]{%
    \includegraphics[]{figures/comp-graph}}
  \qquad
  \subbottom[Backward mode.\label{fig:comp-graph-bw}]{%
    \includegraphics[]{figures/comp-graph-backward}}
  \caption{Computation graph and intermediate expressions of the expression \protect\jlinl{g(sin(x),
      y)}, together with the derivative graphs in forward- and backward mode.  Dashed arrows
    indicate re-use of forward values in the derivative graph.}
  \label{fig:comp-graph}
\end{figure}

In this setting, forward-mode AD is simply an efficient way to calculate the \emph{Jacobian-vector
  product} \(J(x) \Delta\), or equivalently the total derivative at \(x\) for a fixed perturbation
\(\Delta\), avoiding full matrix multiplication.  Appling this to all all basis vectors, we get back
the gradient.  Backward mode, on the other hand, calculates the product of the Jacobian with a dual
vector.  This, in fact, is nothing else than a \emph{vector-Jacobian product} with the transposed
Jacobian.  Recovering the (transposed) gradient of a loss function of type \(\RR^N \to \RR\) then
reduces to evaluating it at a constant scalar output perturbation of \(1\).  Notably, this in
involves only one pass over the graph, while in forward mode, \(N\) passes are required.  For this
reason, backward mode enjoys a much more prominent role in gradient-based machine learning.

\newthought{The practical implementation} of AD in programming languages opens up another set of
possible choices.  One way is to use an external, compiler-based system that transforms a complete
program in a subset of a standard programming language (e.g., Tapenade, which transpiles Fortran and
C code \parencite{tapenadedevelopers2019tapenade}) or in a custom specification, as is done in Stan
\parencite{carpenter2015stan}.  But both of these examples are really applied in niche cases: large
numeric simulations, and log-densities in a probabilistic model.  Moreover, these systems lack
flexibility in programming, especially concerning abstractions and interaction with other libraries,
and require external tooling besides a main programming language.  Recently, the Swift for
TensorFlow project \parencite{tensorflowdevelopers2018swift,hong2018graph} introduced a modern
variant of this by extending the compiler of the Swift programming language with facilities to
perform automatic differentiation internally, and some features to simplify graph operations
required by TensorFlow.

The second possibility is \emph{operator overloading}.  Forward mode can rather easily be added to
any existing programming language which has a sufficiently extensible system for overloading
mathematical operators by implementing dual numbers (see page~\pageref{sec:dual-numbers}).  This can
be done using ad-hoc polymorphism with traits \parencite{amin2016dependent} or type classes
\parencite{wadler1989how}, or by dynamic dispatch, which is what is used in Python and Julia.  The
latter is especially versatile in this respect, since every function can be extended to a new type
of dual numbers by simply adding a method; unlike in Python, where only certain operators are open
to extension~-- a fundamental limitation of its single dispatch, object oriented approach.

\begin{figure}[t]
  \centering
  \includegraphics{figures/wengert-list}
  \caption{Wengert list of the example function \protect\jlinl{g(sin(x), y)} introduced above.
    Every intermediate variable becomes an element, linked through pointers.  The gradient can be
    calculated by backward traversal and accumulating the adjoint values as metadata in the list
    elements.}
  \label{fig:wengert-list}
\end{figure}

Backward-mode AD can be implemented using operator overloading as well, but this requires more
effort.  Since adjoint values cannot be simply threaded through in parallel to forward evaluation,
one needs to build up a data structure during the forward pass, which can at the end be traced back
in reverse order.  One possibility of doing this is to use closures (function objects capturing an
environment), but the usage of many higher order functions might lead to unwanted heap allocation
and makes understanding harder.

The alternative is to use a tape structure, or \emph{Wengert list} \parencites[][section
3]{baydin2018automatic}.  On such a list, the computation graph is stored in topological order with
pointers between elements, as shown in figure~\ref{fig:wengert-list}.  The Wengert list can also be
constructed through an operator overloading approach, which is exactly what graph-based machine
learning frameworks do: PyTorch \parencite{paszke2017automatic}, TensorFlow
\parencite{abadi2015tensorflow} in eager mode, DyNet \parencite{neubig2017dynet}, and Chainer
\parencite{tokui2015chainer}.  In these, the programmer interacts with a library mirroring the usual
numerical functions, but operating on a special \enquote{variable} or \enquote{tensor} type.  These
operations are overloaded so that function calls, in addition to performing the primal calculations,
are stored either explicitly on a global Wengert list structure, or implicitly in the constructed
expression objects.  Then, one can start a backward pass from any leaf to propagate back derivatives
to the roots of the computation graph, by following the edges and summing up adjoint values in
parent nodes' metadata.  JAX \parencite{bradbury2018jax} carries the idea further and allows general
composable source transformations to implement not only differentiation, but also vectorization,
parallelization, and other syntactic abstractions over functional programs written in Python, over a
unified intermediate representation that is recovered from an original function by tracing.

This style of implementation has limitations, though: it requires building up many objects at
run-time, and is completely oblivious of control structures.  Additionally, the code expressing
differentiable functions has to be written entirely in the DSL, in a library-aware fashion,
preventing the usage of third-party functions and language features, and forcing the user to adhere
to certain semantic constraints that cannot be verified statically by the host language.  TensorFlow
in graph mode addresses some of these points.  It builds up a complete expression graph, which is
differentiated symbolically, and is therefore somewhat in the middle between operator overloading
(since the graph is still a run-time data structure) and a static transformation (the resulting
graph is not interpreted in the host language, but converted to run on an \enquote{accelerator},
which can one of several kinds of processing device~-- CPU, GPU, TPU,\ldots).  It still requires to
stick to the provided expression types and library functions, though.

Efforts to overcome these limitations lead to the third kind of approach: language-internal
\emph{source transformation}.  Recent work in Julia \parencite{innes2018don} has shown that the
available metaprogramming mechanisms (described in section~\ref{sec:comp-metapr-julia}) allow to
systematically derive \enquote{adjoint programs} for arbitrary user-provided Julia programs, given
only a set of \emph{primitive adjoints} (such as derivatives of built-in functions).  This approach
works purely structurally on the Julia IR, employing generated functions to analyze functions' code
and transform them completely, including third-party functions and data types, and control flow.
The key insight here is that SSA-form IR already resembles the structure of Wengert lists, extended
by branches.  As in building up reverse computation graphs, the adjoint code will therefore invert
the control flow of the basic blocks in the primal function, taking into account that data flow may
involve dynamic dependencies.  Differentiation through data types and closures is supported via a
unified treatment of them in a tuple-like form, with constructors and accessors (inspired by
cons-cells in Lisp).

An implementation of this principle has been released as the \juliapackage{Zygote.jl}
package\footnote{\url{https://github.com/FluxML/Zygote.jl}}.  In similar spirit, there is also work
on directly differentiating the LLVM intermediate representation, by extending the compiler pipeline
with a differentiation pass that comes after all language-specific and high-level optimizations
\parencite{moses2020instead}, released as the Enzyme
project\footnote{\protect\url{https://enzyme.mit.edu/}}.  Furthermore, there are applications that
use the same techniques for other purposes, like sparsity detection \parencite{gowda2019sparsity} or
concolic execution \parencite{churavy2019vchuravy} (cf. discussion in
section~\ref{sec:irtracker-eval}).

Internal source-based methods can therefore be composable, extensible, and more user-friendly, since
no special treatment of programs to be differentiated is required: primal functions can be
implemented as any other regular function in the host language.  A source-transformation approach
also completely avoids the obscure issue of \enquote{perturbation confusion}, which leads to
hard-to-find errors when using nested differentiation with dual numbers
\parencite{baydin2018automatic,manzyuk2019perturbation}.

As a concluding note, all these graph operations reveal that automatic differentiation is really
only a special case of message passing algorithms in computation graphs
\parencite{minka2019automatic}.  Other learning methods that can be described as message passing are
optimization algorithms \parencite{ruozzi2011message,dauwels2005steepest} and a variety of
variational approximations \parencite{winn2005variational,minka2005divergence}.  Hence, it is no
surprise that computation graphs play a large role as the foundation of other learning algorithms
for probabilistic models, such as described below.

%%% Local Variables: 
%%% TeX-master: "main"
%%% End: