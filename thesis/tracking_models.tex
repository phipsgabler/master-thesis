\chapter{Graph Tracking in Probabilistic Models}
\label{cha:graph-track-prob}

The system described in chapter~\ref{cha:impl-dynam-graph}, implemented in a Julia package
\irtrackerjl{}, can now be utilized for the analysis of probabilistic models written in \dppljl{},
and for posterior inference in \turingjl{}.  This part of the work is realized in another package,
\autogibbsjl{}, which is available as open-source
code\footnote{\url{https://github.com/phipsgabler/AutoGibbs.jl}}.  There are two applications
provided, built on top of the graph tracking functionality: first, dependency analysis of random
variables in a model can be performed.  This results in the complete graphical model for static
models, and a slice of it for dynamic models.  The resulting graph can be plotted for visualization.
Second, given the dependency graph, the conditional likelihoods of unobserved variables in static
models can be extracted.  With these, analytic Gibbs conditionals can be derived and used in
\turingjl{}'s within-Gibbs sampler.

\section{Dependency Analysis in Dynamic Models}
\label{sec:dependency-analysis}

In order to use \irtrackerjl{} to extract the dependencies in a probabilistic model written in
\dppljl{}, we need to remember the structure of such models, which was introduced in
section~\ref{sec:prob-prog}: there is one evaluator function, into which the original code is
transformed, and which evaluates the model in different modes.  This function has the same structure
as the original code, but adds some more complicated book-keeping logic to it, and transforms the
tilde statements into function calls with some additional metadata.  Furthermore, when calling the
model as a callable object, there are several layers of dispatch (about five layers of nesting,
depending on the arguments), until the real evaluator function is actually hit.  On the other hand,
there is no further nesting involved beyond the evaluator function~-- \turingjl{} simply does not
support nested models, for technical reasons.

Therefore, we at first need to introduce an \irtrackerjl{} context that will record all the internal
function calls down to the evaluator function, and stop there.  Similar to the
\jlinl{DepthLimitContext} demonstrated on page~\pageref{lst:depthlimitcontext}, the main task here
is to overload the \jlinl{canrecur} method to stop at the right call.  This can easily be done by
introducing a helper predicate function \jlinl{ismodelcall} that dispatches on the involved types.
Next, we notice that the resulting computation graph consists of a nested and quite unusable
structure, due to the initial levels of nesting.  To work with the model code, we need to strip the
outer layers off the inner node containing the trace of the evaluator function.  Thirdly, many of
the statements in the trace of the evaluator function do not have relevance for dependency
analysis~-- like those that stem from internal calculations done by the model, or statements that
were written by the user but to not lie on the dependency graph, such as debugging statements or the
lowered code of for loops, in some cases.  These we can strip off in advance, so as to clean the raw
dependency trace.  These three preparation steps are put together in one method:
\begin{lstlisting}
function slicedependencies(model::Model{F}, args...) where {F}
    trace = trackmodel(model, args...)
    strip = strip_model_layers(F, trace)
    slice = strip_dependencies(strip)
    return slice
end
\end{lstlisting}
Here, \jlinl{trackmodel} extracts the computation graph with the context for models tracking,
\jlinl{strip_model_layers} removes the outer method calls, and \jlinl{strip_dependencies} removes
all SSA code that is not on the dependecy graph spanned by the sampling statements.

The final and most intricate step is to add all the remaining SSA statements to a new graph
structure, that describes a more domain-specific representation.  In this \jlinl{Graph} type, only
assumption, observation, call, and constant nodes remain, containing relevant metadata such as their
values, variable names, and distribution objects.  In addition, the object stores intermediate
information used during its construction, such as the mapping between newly generated and original
references.  The graph construction is implemented in a function \jlinl{makegraph}, and we finally
have one exported function
\begin{lstlisting}
function trackdependencies(model, args...)
    slice = slicedependencies(model, args...)
    return makegraph(slice)
end
\end{lstlisting}
There are two complications regarding \jlinl{makegraph}.  For one, model arguments are handled
specially by \dppljl{}~-- there are some internal arguments added, and the original arguments are
inspected to allow to run the same model in generative or posterior mode.  This part needs to be
sorted out, so that the passed argument values are correctly set up as constants in the dependency
graph, but since all information is present, the task is resolved by correctly identifying the
arguments and restructuring their contents into the right form.

The other problem is the handling of mutation, and tracking of modified array elements.  For
example, a hidden Markov model might contain code like this:
\begin{lstlisting}
s = zeros(Int, N)
s[1] ~ Categorical(K)
for i = 2:N
    s[i] ~ Categorical(T[s[i-1]])
end
\end{lstlisting}
In order to express the dependency between successive elements of \jlinl{s}, an empty array is first
set up, and then subsequently populated by the results of the tilde statements describing the Markov
process.  In this form, only the individual variables \jlinl{s[i]} are recognized by the model
language.  Internally, the tilde statements are translated to array assignments of the form
\jlinl{s[i] = tilde_assume(...)}, but with additional lowering of the involved arguments, after
which the corresponding IR will look approximately like this:
\begin{lstlisting}
%9 = %i - 1                                  # i - 1
%10 = getindex(%s, %9)                       # s[i - 1]
%11 = getindex(%T, %10)                      # T[s[i - 1]]
%12 = VarInfo{:s}(((%i,),))
%13 = Categorical(%11)
%14 = tilde_assume(..., %13, ..., %12, ...)  # %14 ~ %13
%15 = setindex!(%s, %14)                     # s[i] = %14
\end{lstlisting}
(to be understood symbolically, not as real SSA~-- several statements have been collapsed).  We see
that the direct association between the variable \jlinl{s} is not preserved in the line of the tilde
method, but spread over multiple statements. Even worse, since all statements for the different
\jlinl{s[i]} result in mutations of \jlinl{\%s}, the immediate dependency between \jlinl{s[i]} and
\jlinl{s[i-1]} is not available structurally, but must be recovered dynamically.

The \jlinl{makegraph} implementation solves this by successively identifying mutated arrays
representing random variables by inspecting the indexing calls around tilde statements, and storing
the association between the assumption and the array elements.  This part of the procedure is the
most intricate one, and not complete; there may exist cases where mutation is able to
\enquote{circumvent} the dependecy analysis.  Additionally, the matching between indexing arguments
involves some careful treatment of variable names; the existing \dppljl{} API for this functionality
is not very comprehensive.  Due to this, the current implementation of \autogibbsjl{} currently only
supports \enquote{simple} indexing by one tuple of integers.  Other, more general indexing styles
allowed in Julia could be added in future extensions.  Furthermore, broadcasting tilde statements,
that are supported in \dppljl{}, are not supported by \autogibbsjl{} either.

\newthought{As an example} for the resulting graphs, take the two simple models in
listing~\ref{lst:dependency-examples}.  The pretty-printed dependency \jlinl{Graph} objects
extracted from them are shown in listing~\ref{lst:trace-examples} below.  We can see that the model
arguments for observations occur as constant values, and all of the intermediate transformation
visible in the original model definitions are observed.  From this structure, \autogibbsjl{} can
construct output in the Dot graph format and vizualized using GraphViz \parencite{gansner2000open}.
The visual outputs of the example models is shown in figure~\ref{fig:geom-deps}\todo{update \(p\) to
  \(\pi\)}.

\begin{lstfloat}[p]
\begin{lstlisting}[style=lstfloat]
@model function bernoulli_mixture(x)
    w ~ Dirichlet(2, 1/2)
    π ~ DiscreteNonParametric([0.3, 0.7], w)
    x ~ Bernoulli(π)
end

@model function hierarchical_gaussian(x)
    λ ~ Gamma(2.0, inv(3.0))
    m ~ Normal(0, sqrt(1 / λ))
    x ~ Normal(m, sqrt(1 / λ))
end
\end{lstlisting}
  \caption{Two simple example models: a mixture of two Bernoulli random variables with fixed
    probabilities, and a Gaussian model with conjugate prior.  Both models are defined over one
    single observation.}
  \label{lst:dependency-examples}
\end{lstfloat}

\newsavebox{\bernoullitrace}
\begin{lrbox}{\bernoullitrace}
\begin{lstlisting}[style=lstfloat]
⟨2⟩ = false
⟨3⟩ = Dirichlet(2, 0.5) → Dirichlet{Float64}(alpha=[0.5, 0.5])
⟨4⟩ = w ~ ⟨3⟩ → [0.826304431175434, 0.17369556882456608]
⟨5⟩ = DiscreteNonParametric([0.3, 0.7], ⟨4⟩) → DiscreteNonParametric{...}(
        support=[0.3, 0.7], p=[0.826304431175434, 0.17369556882456608])
⟨6⟩ = π ~ ⟨5⟩ → 0.3
⟨7⟩ = Bernoulli(⟨6⟩) → Bernoulli{Float64}(p=0.3)
⟨8⟩ = x ~ ⟨7⟩ ← ⟨2⟩
\end{lstlisting}
\end{lrbox}
\newsavebox{\gaussiantrace}
\begin{lrbox}{\gaussiantrace}
\begin{lstlisting}[style=lstfloat]
⟨2⟩ = 1.4
⟨3⟩ = Gamma(2.0, 0.3333333333333333) → Gamma{Float64}(
        α=2.0, θ=0.3333333333333333)
⟨4⟩ = λ ~ ⟨3⟩ → 0.9257859525673857
⟨5⟩ = /(1, ⟨4⟩) → 1.0801632896100921
⟨6⟩ = sqrt(⟨5⟩) → 1.0393090443222806
⟨7⟩ = Normal(0, ⟨6⟩) → Normal{Float64}(μ=0.0, σ=1.0393090443222806)
⟨8⟩ = m ~ ⟨7⟩ → 1.8505166567138398
⟨9⟩ = /(1, ⟨4⟩) → 1.0801632896100921
⟨10⟩ = sqrt(⟨9⟩) → 1.0393090443222806
⟨11⟩ = Normal(⟨8⟩, ⟨10⟩) → Normal{Float64}(
         μ=1.8505166567138398, σ=1.0393090443222806)
⟨12⟩ = x ~ ⟨11⟩ ← ⟨2⟩
\end{lstlisting}
\end{lrbox}
\begin{lstfloat}[p]
  \loosesubcaptions
  \subbottom[Trace of \texttt{bernoulli\_mixture(false)} (some type parameters not shown).]{%
    \usebox{\bernoullitrace}}
  \subbottom[Trace of \texttt{hierarchical\_gaussian(1.4)}.]{%
    \usebox{\gaussiantrace}}
  \caption{Traced structure of the two example models introduced above.  Values in \(\langle\)angle
    brackets\(\rangle\) denote intermediate values (similar to SSA variables), and right arrows
    denote the resulting values of function calls.  The left arrow indicates the source of the
    observed value.}
  \label{lst:trace-examples}
\end{lstfloat}

\FloatBlock

\begin{figure}[p]
  \centering
  \subbottom[][\texttt{bernoulli\_mixture(false)}]{%
    \includegraphics[width=0.49\textwidth]{figures/bernoulli_dependencies}}
  \subbottom[][\texttt{hierarchical\_gaussian(1.4)}]{%
    \includegraphics[width=0.49\textwidth]{figures/gaussian_dependencies}}
  \caption{Dependency graphs of the models in listing~\ref{lst:dependency-examples}, generated by
    \autogibbsjl{} and rendered by GraphViz.  More information, such as node values, is stored in
    the real model graph, but not printed for better readability.  Circular nodes denote tilde
    statements, while deterministic intermediate values, corresponding to normal SSA statements, are
    written in rectangles.}
  \label{fig:geom-deps}
\end{figure}


\section{Automatic Calculation of Gibbs Conditionals}
\label{sec:automatic-conditionals}

The ultimate contribution of this work is to utilize the dependency extraction system to extend
\turingjl{} with JAGS-style automatic calculation of Gibbs Conditionals.  In JAGS (and its sibling,
BUGS) conditional extraction works over a wide range of variable types \parencite{plummer2003jags}
by symbolic analysis and recognition of several patterns (e.g., conjugate distributions from
exponential families, log-concave or compactly supported distributions; see
\textcite{lunn2000winbugs}.), which is possible since the class of models is constrained by the
modelling language, and available in completely structured form.\todo{fix parskips, see
  background.tex:445}

In \turingjl{}, models are much less restricted, and the symbolic form has to recovered from
outside, as we have seen.  To focus on the principal ideas and not to extend the scope too much, the
implementation described in this section was restricted to finite, discrete conditionals, which are
trivial to sample from, given the respective log-density.  Since the construction of conditional
log-densities is independent from the normalization step, though, this can serve as a starting point
for further, more general conditional samplers, as those in JAGS and BUGS.  Additionally, and this
is a more fundamental limitation, the models to which the extraction algorithm can be applied must
be static in a specific sense: the whole Markov blanket of the variable in question must be unique,
and reachedable within one run of model tracking.  A large fraction of the models used in practise
do fulfill this condition, though.  As this problem is difficult so solve in general, the same
constraint applies to JAGS and BUGS, which makes \autogibbsjl{} not more limited than these.

The implementation of the conditional extraction system involves three main steps:
\begin{enumerate}
  \firmlist
\item Extracting the symbolic form of the conditional likelihood of Markov blankets in a given
  dependency graph.
\item Constructing closures calculating the normalized discrete conditionals from these likelihoods.
\item Providing a Gibbs-component sampler for \turingjl{}, that can utilize the resulting
  conditional distributions.
\end{enumerate}
The third step turned out to be the easiest, since the sampling system of \turingjl{} is designed to
be extensible.  Ideally, a Gibbs-conditional sampler would have first been added to \turingjl{} and
then simply been reused for \autogibbsjl{}; in practice, it worked out the other way round, and the
\autogibbsjl{} sampler has, in generalized form, been added to \turingjl{} afterwards (without the
automatic extraction, only supporting user-provided conditional distributions).

\newsavebox{\bmlikelihoods}
\begin{lrbox}{\bmlikelihoods}
\begin{lstlisting}[style=lstfloat]
⟨2⟩ = 1.4                  ⤳ 1.4
⟨3⟩ = Dirichlet(2, 0.5)    ⤳ Dirichlet(2, 0.5)
⟨4⟩ = w ~ ⟨3⟩              ⤳ logpdf(Dirichlet(2, 0.5), θ[w])
⟨5⟩ = DNP([0.3, 0.7], ⟨4⟩) ⤳ DNP([0.3, 0.7], θ[w])
⟨6⟩ = π ~ ⟨5⟩              ⤳ logpdf(DNP([0.3, 0.7], θ[w]), θ[π])
⟨7⟩ = Bernoulli(⟨6⟩)       ⤳ Bernoulli(θ[p])
⟨8⟩ = x ~ ⟨7⟩ ← ⟨2⟩       ⤳ logpdf(Bernoulli(θ[p]), θ[x])
\end{lstlisting}
\end{lrbox}
\newsavebox{\hglikelihoods}
\begin{lrbox}{\hglikelihoods}
\begin{lstlisting}[style=lstfloat]
⟨2⟩ = 1.4                 ⤳ 1.4
⟨3⟩ = Gamma(2.0, 1/3)     ⤳ Gamma(2.0, 1/3)
⟨4⟩ = λ ~ ⟨3⟩             ⤳ logpdf(Gamma(2.0, 1/3), θ[λ])
⟨5⟩ = /(1, ⟨4⟩)           ⤳ /(1, θ[λ])
⟨6⟩ = sqrt(⟨5⟩)           ⤳ sqrt(/(1, θ[λ]))
⟨7⟩ = Normal(0, ⟨6⟩)      ⤳ Normal(0, sqrt(/(1, θ[λ])))
⟨8⟩ = m ~ ⟨7⟩             ⤳ logpdf(Normal(0, sqrt(/(1, θ[λ]))), θ[m])
⟨9⟩ = /(1, ⟨4⟩)           ⤳ /(1, θ[λ])
⟨10⟩ = sqrt(⟨9⟩)          ⤳ sqrt(/(1, θ[λ]))
⟨11⟩ = Normal(⟨8⟩, ⟨10⟩)  ⤳ Normal(θ[m], sqrt(/(1, θ[λ])))
⟨12⟩ = x ~ ⟨11⟩ ← ⟨2⟩    ⤳ logpdf(Normal(θ[m], sqrt(/(1, θ[λ]))), θ[x])
\end{lstlisting}
\end{lrbox}
\begin{figure}[t]
  \loosesubcaptions
  \subbottom[\texttt{bernoulli\_mixture(false)}]{\usebox{\bmlikelihoods}}
  \subbottom[\texttt{hierarchical\_gaussian(1.4)}]{\usebox{\hglikelihoods}}
  \caption{Association of the dependency graph of the example models from
    listing~\ref{lst:dependency-examples} with intermediate symbolic functions.  The expressions on
    the right are implicit functions of \protect\jlinl{θ}.  (\texttt{DNP} is used instead of
    \texttt{DiscreteNonParametric} to avoid breaking lines.)}
  \label{fig:continuations}
\end{figure}

Step 1, the symbolic extraction of likelihood functions, is implemented by first converting the full
trace into a symbolic joint log-density.  Therefor the expression of each node in the dependency
graph is associated with a corresponding symbolic representation of a function of the \enquote{trace
  dictionary} \jlinl{θ}, which holds the values of the random variables by name (this is to view the
probabilistic model as a joint distribution over trace dictionaries).  This is done in the following
simple fashion:
\begin{itemize}
  \firmlist
\item References to call nodes or constant nodes (\jlinl{⟨i⟩ = x}) are inlined.
\item References to tilde nodes (\jlinl{⟨j⟩ = v ~ D}) are converted to dictionary lookups: \jlinl{θ[v]}.
\item Call nodes are converted to functions from the trace dictionary to a
  function call on the converted references: \jlinl{f(⟨i⟩, ⟨j⟩)} \(\leadsto\) \jlinl{f(x, θ[v])}.
\item Tilde nodes are converted to log-density evaluations of their values given the corresponding
  distribution: \jlinl{⟨j⟩ = v ~ D} \(\leadsto\) \jlinl{logpdf(D, θ[v])}
\end{itemize}
All resulting expressions are thereby to be understood as implicit functions of \jlinl{θ}.  These
new expression function objects can then be numerically evaluated as log-densities for given values
of all random variables.  For illustration, the joint densities of the \jlinl{bernoulli_mixture} and
\jlinl{hierarchical_gaussian} models introduced above in listing~\ref{lst:dependency-examples}, are
associated with corresponding symbolic functions as shown in figure~\ref{fig:continuations}\todo{fix
  caption alignment}.  By adding the log-likelihoods for each tilde statement, we get the symbolic
log-joint density as, for example,
\begin{lstlisting}
logpdf(Gamma(2.0, 0.333333), θ[λ]) + 
  logpdf(Normal(0, sqrt(/(1, θ[λ]))), θ[m]) + 
  logpdf(Normal(θ[m], sqrt(/(1, θ[λ]))), θ[x]),
\end{lstlisting}
corresponding to the density over \(\lambda\), \(m\), and \(x\), factorizd as
\begin{equation}
  p(\lambda, m, x) = p(\lambda) \, p(m \given \lambda) \, p(x \given m, \lambda).
\end{equation}
From this we can then derive conditionals in the usual way of normalizing the proportional
conditional, which can be obtained by removing all terms of the joint factorization that do not
depend on the conditioned variable:
\begin{equation}
  \begin{aligned}
    p(m \given \lambda, x) &\propto p(m \given \lambda) \, p(x \given m, \lambda), \\
    p(\lambda \given m, x) &\propto p(\lambda) \, p(m \given \lambda) \, p(x \given m, \lambda),
  \end{aligned}
\end{equation}
which in more technical terms are given through the \emph{Markov blanket} of \(m\) and \(\lambda\)
\parencites[section 24.2]{murphy2012machine}[section 4.5]{koller2009probabilistic}.

The crucial problem here is, of course, to find the normalization factor, as always in Monte Carlo
methods.  Normalization could, for example, be implemented by analysing the structure of the
resulting expression and detecting conjugacies, such as the normal/normal-gamma relationship between
\(m\), \(\lambda\), and \(x\) above.  The simplest possible case, however, occurs when when a
conditioned variable has finite support; and as mentioned above, this is what has been implemented
out in this work.  For example, \(p\) in the \jlinl{bernoulli_mixture} model is such a finitely
supported variable~-- we get
\begin{equation}
    p(\pi \given w, x) = \frac{p(w) \, p(\pi \given w) \, p(x \given \pi)}{
      \sum_{\varpi \in \{0.3, 0.7\}}p(w) \, p(\varpi \given w) \, p(x \given \varpi)}
\end{equation}
Since the distribution of every variables is preserved in the dependency graph, we now can do the
same thing programmatically, and turn the symbolic log-density into a distribution object by simply
tabulating the values of the denominator through evaluating of the expression over the whole support
of \(\pi\), the set \(\{0.3, 0.7\}\), and summing it up to get the normalization factor.  (This uses
the interface of distribution objects from the \juliapackage{Distributions.jl} package, which have a
\jlinl{support} method whose result is an iterable.)

Concretely, the construction works as follows, finalizing step 2 of the above scheme, exemplified by
\jlinl{bernoulli_mixture}:
\begin{enumerate}
  \firmlist
\item Find the likelihood expressions that match a given conditioned variable (this includes indexed
  variables subsumed by a parent, like \jlinl{v[i]} and \jlinl{v}), and their distribution:
  \begin{equation*}
    \begin{aligned}
      \ell_{1} &= \mathtt{logpdf(DNP([0.3, 0.7],\theta[w]), \theta[\pi])}. \\
      \mathcal{D} &= \mathtt{DNP([0.3, 0.7], \theta[w])}.
    \end{aligned}
  \end{equation*}
\item For each of these (sub-)variables, collect the likelihoods of their children variables, thus
  completing the Markov blanket:
  \begin{equation*}
    \ell_{2} = \mathtt{logpdf(Bernoulli(\theta[\pi]), \theta[x])}
  \end{equation*}
  The complicated part of this and the previous step is the correct matching of indexed variables in
  the trace dictionary: forms like \jlinl{θ[v][1]} and \jlinl{θ[v[1]]} need to be resolved correctly
  to the same value.
\item Construct for each a closure function that takes as an argument a fixed trace dictionary,
  tabulates the conditional log-likelihood over it with the conditioned variable fixed to all values
  of its support, and normalizes the result:
  \begin{equation*}
    \begin{aligned}
      &\theta \mapsto \{ \\
      &\quad \Omega = \mathtt{support}(\mathcal{D}) \\
      &\quad \mathtt{table} = \left[\operatorname{eval}(\ell_{1}, \theta[\pi \leadsto \varpi]) +
        \operatorname{eval}(\ell_{2}, \theta[\pi \leadsto \varpi]) \mid \varpi \in \Omega \right] \\
      &\quad \distr{DNP}(\Omega, \operatorname{softmax}(\mathtt{table})) \\
      &\}
    \end{aligned}
  \end{equation*}
  (whereby \(\operatorname{softmax}(x) = \broadcast{\exp}(x) / \sum_i \exp(x_{i})\) is the
  normalization operation on log-probabilities).
\end{enumerate}
The result of this process is a collection of closures that represent the conditional likelihoods as
\enquote{kernels}: functions from conditioned-on variables to distribution objects.  These closures
can then be used to construct a conditional sampler for usage in \turingjl{}'s \jlinl{Gibbs}
sampler, in combination with other samplers for the continuous variables.

\newthought{As for potential improvements}, there is of course a wide range of possibilities, as the
current implementation is a most primitive one.  As has been mentioned before, further classes of
random variables beyond those with finite support could be handled, using methods and heuristics as
in BUGS or JAGS.  This could even involve symbolic methods like those in AutoConj
\parencite{hoffman2018autoconj}. More generally, variance-reducing transformation, as those in
\textcite{murray2017delayed}, are applicable.  For computational efficiency, a parallel Gibbs
sampler \parencite{gonzalez2011parallel} could be constructed, improving scalability with increasing
data size (i.e., numbers of observations).  Or, as in Gen, a variant of \enquote{argument diffs}
could be devised to prevent unnecessary re-evaluation of model parts \parencites[see][section
1.2.3]{cusumano-towner2020gen}{becker2020dynamic}.  Finally, the evaluation of the conditional
closures, which is currently performed by simple interpreation of expressions, could be sped up by
compiling them to Julia methods, or even better by reusing the SSA-like structure to emit Julia IR
directly.

Realistically, though, I consider it more worthwhile to follow a different approach, like the one
outlined in section~\ref{sec:future-work} below, and moving away from working on a trace-based
reconstruction and to a domain-specific intermediate representation with generalized transformation
capabilities.  On such a representation, all of the named ideas still apply, but it would have the
advantage of being more invariant to a specific inference system, and be able to handle more general
probabilistic programs (foremost, not only static ones).


\section{Evaluation}
\label{sec:autogibbs-eval}

To begin with a qualitative assessment, it must be admitted that \autogibbsjl{} is, when run
manually and only once, empirically so noticeably slow, that a user may be tempted to dismiss it
outright (concretely speaking, extraction of one conditional for some not-so-large models takes
\(20\) to \(200\) seconds on the author's laptop).  This is a valid point, but two counter-arguments
must be considered.  For one, the implementation is a preliminary one, more conceptual than
optimized.  Much of the slow-down could be mitigated by just improving key parts of \autogibbsjl{}
and \irtrackerjl{}.

In addition to that, one must realize where this appearent slowness comes from: namely, from
compilation, and therein primarily type inference, of the functions handling all the strongly typed
expression trees.  Besides the possibility of just optimizing these further, the following fact is
most important to realize: compilation takes place only once~-- as soon as a conditional is
constructed, it can be reused in arbitrarily many sampling runs of the same model.  The finished
conditionals then do not take so much time anymore, quite the contrary: they are much faster than
other within-Gibbs samplers, since they only involve evaluating a fixed expression, constructing a
distribution, and sampling from it once (and even this could be sped up further).  This makes it
possible to sample much longer chains in the same time, which is an overall advantage.

So, to conclude, while the implementation in current form is not very applicable in practice for all
cases, it is very much so in principle.  Based on the lessons learned through this work, further
contributions to Gibbs sampling in \turingjl{} are already planned (although not necessarily based
on \autogibbsjl{}).

\newthought{For a more {q}uantitative} point of view, let us now turn to some empirical evaluations.
Besides several unit tests for correctness of the derived dependencies and conditionals on a variety
of models chosen to test certain features and corner cases, an experimental comparison of
\autogibbsjl{} and existing \turingjl{} samplers has been conducted.  For this purpose, three
off-the-shelf Bayesian models were chosen: a Gaussian mixture model (GMM) with known variances and
priors over cluster centers, weights, and assignments \parencite[section 6.2]{marin2007bayesian},
\begin{equation}
  \label{eq:gmm}
  \begin{aligned}
    w &\from \distr{Dirichlet(K)} \\
    z_{n} &\from \distr{Categorical}([1, \ldots, K], w), \quad n = 1, \ldots, N \\
    \mu_{k} &\from \Normal(0, \sigma_{1}), \quad k = 1, \ldots, K \\
    x_{n} &\from \Normal(\mu_{z_{n}}, \sigma_{1}), \quad n = 1, \ldots, N;
  \end{aligned}
\end{equation}
a hidden Markov model (HMM) with known variances and priors over transition and emission
probabilities \parencite[section 7.3]{marin2007bayesian},
\begin{equation}
  \label{eq:hmm}
  \begin{aligned}
    T_{k} &\from \distr{Dirichlet}(K), \quad k = 1, \ldots, K \\
    m_{k} &\from \Normal(k, \sigma_{1}), \quad k = 1, \ldots, K \\
    s_{1} &\from \distr{Categorical}([1, \ldots, K], [1/K, \ldots, 1/K]) \\
    s_{k} &\from \distr{Categorical}([1, \ldots, K], T_{s_{k-1}}), \quad k = 2, \ldots, N \\
    x_{k} &\from \Normal(m_{s_{k}}, \sigma_{2}), \quad k = 1, \ldots, N;
  \end{aligned}
\end{equation}
and an infinite mixture model (IMM) in stick-breaking construction, but otherwise of the same form
as the finite GMM above, to represent a nonparametric example \parencite[section
2.2]{hjort2010bayesian}:
\begin{equation}
  \label{eq:imm}
  \begin{aligned}
    w &\from \distr{TruncatedStickBreakingProcess(\alpha, K)} \\
    z_{n} &\from \distr{Categorical}([1, \ldots, K], w), \quad n = 1, \ldots, N \\
    \mu_{k} &\from \Normal(0, \sigma_{1}), \quad k = 1, \ldots, K \\
    y_{n} &\from \Normal(\mu_{z_{n}}, \sigma_{2}), \quad n = 1, \ldots, N.
  \end{aligned}
\end{equation}
The models are implemented in \dppljl{} as shown in listing~\ref{lst:evaluation-models}.
\begin{lstfloat}[p]
\begin{lstlisting}[style=lstfloat]
@model function gmm(x, K)
    N = length(x)
    w ~ Dirichlet(K, 1/K)  # Cluster association prior
    z ~ filldist(Categorical(w), N)  # Cluster assignments
    μ ~ filldist(Normal(0.0, s1_gmm), K)  # Cluster centers

    for n = 1:N
        x[n] ~ Normal(μ[z[n]], s2_gmm)  # Observations
    end
end

@model function hmm(x, K, ::Type{T}=Float64) where {T<:Real}
    N = length(x)

    T = Vector{Vector{X}}(undef, K)
    for i = 1:K
        T[i] ~ Dirichlet(K, 1/K)  # Transition probabilities
    end
    
    s = zeros(Int, N)
    s[1] ~ Categorical(K)
    for i = 2:N
        s[i] ~ Categorical(T[s[i-1]])  # State sequence
    end
    
    m = Vector{T}(undef, K)
    for i = 1:K
        m[i] ~ Normal(i, s1_hmm)  # Emission probabilities
    end
    
    x[1] ~ Normal(m[s[1]], s2_hmm)
    for i = 2:N
        x[i] ~ Normal(m[s[i]], s2_hmm)  # Observations
    end
end

@model function imm_stick(y, α, K)
    N = length(y)
    crm = DirichletProcess(α)
    v ~ filldist(StickBreakingProcess(crm), K - 1)
    w = stickbreak(v)  # Cluster weights
    
    z = zeros(Int, N)
    for n = 1:N
        z[n] ~ Categorical(w)  # Cluster assignments
    end

    μ ~ filldist(Normal(0.0, s1_imm), K)  # Cluster centers

    for n = 1:N
        y[n] ~ Normal(μ[z[n]], s2_imm)  # Observations
    end
end
\end{lstlisting}
  \caption{Gaussian mixture model, hidden Markov model, and infinite mixture model using a
    stick-breaking construction.  The two-step calculation of \texttt{w} via \texttt{v} is a
    technicality due to \turingjl{}'s handling of nonparametric models.  The function
    \texttt{stickbreak} normalizes the stick-lengths \texttt{v} into a Dirichlet-like distribution.
    The \texttt{Categorical(p)} constructor automatically infers the support of the categorical
    distribution from the weights as \texttt{1:length(p)}.}
  \label{lst:evaluation-models}
\end{lstfloat}
The three interesting classes of metrics to evaluate are, in the case of this work,
\begin{enumerate}
  \firmlist
\item the \enquote{compilation time} of \autogibbsjl{}, i.e., the time it takes to extract a
  conditional,
\item the sampling speed when used as component of a within-Gibbs sampler, and
\item the quality of the resulting chains, in terms of convergence and variance diagnostics.
  (Although this really measures Gibbs sampling, not the implementation of \autogibbsjl{}, it is a
  relevant comparison for the practitioner.)
\end{enumerate}
Each of the test models involves one discrete and two continuous parameters.  As benchmark for
\autogibbsjl{}'s static conditional (AG), it is compared to \turingjl{}'s Particle Gibbs sampler
(PG), which is also suited to discrete parameters.  Continuous variables are all sampled using
Hamiltonian Monte Carlo (HMC) with hand-tuned parameters per model.  The experiments have been set
up such that each model is evaluated for ten chains of length \(10000\), varying between AG and PG,
and four different values for the number of observations (since these determine the size of the
trace, and thus have an influence on both AG's compile times and the overall sampling time).  PG was
always used with \(100\) particles, since lower values did lead to convergent chains.

Concrete parameters in table~\ref{tab:autogibbs-params}.\todo{more meaningful table}

\begin{table}[t]
  \centering
  \libertineTabular
  \begin{tabularx}{\textwidth}{XXrrr@{\hskip 10mm}rrrr}
    \toprule
     & & \multicolumn{3}{c@{\hskip 10mm}}{\textbf{GMM}} & \multicolumn{3}{c}{\textbf{HMM}} & \multicolumn{1}{c}{\textbf{IMM}} \\
    \midrule
    & HMC Step size & & 0.05 & & & 0.05 & & 0.05 \\
    & HMC Steps & & 10 & & & 10 & & 10 \\
    \midrule
    \textbf{AG + HMC} & Observations & 10 & 25 & 50 & 10 & 25 & 50 & 10 \\
    & Chains & 30 & 30 & 30 & 30 & 30 & 30 & 30 \\
    & Compilations & 3 & 3 & 3 & 3 & 3 & 3 & 3 \\
    \addlinespace
    \textbf{PG + HMC,} & Observations & 10 & 25 & 50 & 10 & 25 & 50 & 10 \\
     & Chains & 10 & 10 & 10 & 10 & 10 & 10 & 10 \\
    \bottomrule
  \end{tabularx}
  \caption{Experimental conditions for evaluating AutoGibbs (AG) agains Particle Gibbs (PG).  Chains
    were always of length \(10000\).  A new static Gibbs conditional was extracted for each block of
    \(10\) chains that was run with the same parameters while Particle Gibbs was varied over the
    three particle sizes.  Particle Gibbs with 50 particles was sometimes killed due to timeouts on
    the server.}
  \label{tab:autogibbs-params}
\end{table}



% extraction times
% Measuring both compilation of the traced code and the conditional calculation.",
% "All 2 or 3 repetitions per data size class are shown."
% Linear fit for time ~ datasize²
% three samples

% sampling times
% subtitle = "Factored by algorithm and number of PG particles"

% diagnostics
% subtitle = "Factored by algorithm and number of particles"

% densities
% subtitle = paste("Factored by number of observations (data size)", "and selected parameters")

% ACFs
% subtitle = "ACF plots for one sample chain per data size"


%%% Local Variables: 
%%% TeX-master: "main"
%%% End: